{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('small_vocab_en.txt', <http.client.HTTPMessage at 0x7fc77079d610>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/tommytracey/AIND-Capstone/master/data/small_vocab_en'\n",
    "filename = 'small_vocab_en.txt'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('small_vocab_fr.txt', <http.client.HTTPMessage at 0x7fc771a240a0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/tommytracey/AIND-Capstone/master/data/small_vocab_fr'\n",
    "filename = 'small_vocab_fr.txt'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "#from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load English data\n",
    "english_sentences = load_data('small_vocab_en.txt')\n",
    "# Load French data\n",
    "french_sentences = load_data('small_vocab_fr.txt')\n",
    "\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sample 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "French sample 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "\n",
      "English sample 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "French sample 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "\n",
      "English sample 3:  california is usually quiet during march , and it is usually hot in june .\n",
      "French sample 3:  california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "\n",
      "English sample 4:  the united states is sometimes mild during june , and it is cold in september .\n",
      "French sample 4:  les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "\n",
      "English sample 5:  your least liked fruit is the grape , but my least liked is the apple .\n",
      "French sample 5:  votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(5):\n",
    "    print('English sample {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('French sample {}:  {}\\n'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    return tokenizer.texts_to_sequences(x), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    return pad_sequences(x, maxlen=length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 344\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "    preprocess(english_sentences, french_sentences)\n",
    "    \n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Built Bidirectional RNN with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Custom Model Loaded\n"
     ]
    }
   ],
   "source": [
    "def custom_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.003\n",
    "    \n",
    "    # Build the layers    \n",
    "    model = Sequential()\n",
    "    # Embedding\n",
    "    model.add(tf.keras.layers.Embedding(english_vocab_size, 128, input_length=input_shape[1],\n",
    "                         input_shape=input_shape[1:]))\n",
    "    # Encoder\n",
    "    model.add(Bidirectional(GRU(128)))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    # Decoder\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(512, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
    "    \n",
    "    opt = Adam(lr=learning_rate)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print('Final Custom Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    \"\"\"\n",
    "    Gets predictions using the final model\n",
    "    :param x: Preprocessed English data\n",
    "    :param y: Preprocessed French data\n",
    "    :param x_tk: English tokenizer\n",
    "    :param y_tk: French tokenizer\n",
    "    \"\"\"\n",
    "    # TODO: Train neural network\n",
    "    model = custom_model(x.shape,y.shape[1],\n",
    "                         len(x_tk.word_index)+1,\n",
    "                         len(y_tk.word_index)+1)\n",
    "    model.summary()\n",
    "    history = model.fit(x, y, batch_size=1024, epochs=23, validation_split=0.2)\n",
    "\n",
    "    \n",
    "    ## DON'T EDIT ANYTHING BELOW THIS LINE\n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "\n",
    "    sentence = 'he saw a old yellow truck'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "\n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('Il a vu un vieux camion jaune')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 15, 128)           25600     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 21, 256)           296448    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 21, 512)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 21, 345)           176985    \n",
      "=================================================================\n",
      "Total params: 828,761\n",
      "Trainable params: 828,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/23\n",
      "108/108 [==============================] - 118s 1s/step - loss: 2.4800 - accuracy: 0.4806 - val_loss: 1.5761 - val_accuracy: 0.6031\n",
      "Epoch 2/23\n",
      "108/108 [==============================] - 102s 949ms/step - loss: 1.4354 - accuracy: 0.6212 - val_loss: 1.1582 - val_accuracy: 0.6803\n",
      "Epoch 3/23\n",
      "108/108 [==============================] - 101s 938ms/step - loss: 1.1479 - accuracy: 0.6783 - val_loss: 0.9721 - val_accuracy: 0.7190\n",
      "Epoch 4/23\n",
      "108/108 [==============================] - 104s 961ms/step - loss: 0.9915 - accuracy: 0.7092 - val_loss: 0.8270 - val_accuracy: 0.7466\n",
      "Epoch 5/23\n",
      "108/108 [==============================] - 103s 954ms/step - loss: 0.8519 - accuracy: 0.7400 - val_loss: 0.6798 - val_accuracy: 0.7894\n",
      "Epoch 6/23\n",
      "108/108 [==============================] - 105s 971ms/step - loss: 0.7007 - accuracy: 0.7806 - val_loss: 0.5598 - val_accuracy: 0.8250\n",
      "Epoch 7/23\n",
      "108/108 [==============================] - 102s 946ms/step - loss: 0.8076 - accuracy: 0.7571 - val_loss: 0.6960 - val_accuracy: 0.7822\n",
      "Epoch 8/23\n",
      "108/108 [==============================] - 105s 969ms/step - loss: 0.6626 - accuracy: 0.7924 - val_loss: 0.4909 - val_accuracy: 0.8487\n",
      "Epoch 9/23\n",
      "108/108 [==============================] - 103s 951ms/step - loss: 0.5237 - accuracy: 0.8349 - val_loss: 0.3732 - val_accuracy: 0.8878\n",
      "Epoch 10/23\n",
      "108/108 [==============================] - 102s 945ms/step - loss: 0.4272 - accuracy: 0.8669 - val_loss: 0.3088 - val_accuracy: 0.9108\n",
      "Epoch 11/23\n",
      "108/108 [==============================] - 102s 949ms/step - loss: 0.3487 - accuracy: 0.8949 - val_loss: 0.2428 - val_accuracy: 0.9302\n",
      "Epoch 12/23\n",
      "108/108 [==============================] - 104s 966ms/step - loss: 0.2909 - accuracy: 0.9138 - val_loss: 0.2059 - val_accuracy: 0.9436\n",
      "Epoch 13/23\n",
      "108/108 [==============================] - 100s 927ms/step - loss: 0.2453 - accuracy: 0.9283 - val_loss: 0.1730 - val_accuracy: 0.9512\n",
      "Epoch 14/23\n",
      "108/108 [==============================] - 101s 932ms/step - loss: 0.2157 - accuracy: 0.9371 - val_loss: 0.1709 - val_accuracy: 0.9531\n",
      "Epoch 15/23\n",
      "108/108 [==============================] - 100s 923ms/step - loss: 0.2701 - accuracy: 0.9187 - val_loss: 0.1567 - val_accuracy: 0.9564\n",
      "Epoch 16/23\n",
      "108/108 [==============================] - 102s 944ms/step - loss: 0.1784 - accuracy: 0.9482 - val_loss: 0.1306 - val_accuracy: 0.9628\n",
      "Epoch 17/23\n",
      "108/108 [==============================] - 100s 924ms/step - loss: 0.1611 - accuracy: 0.9532 - val_loss: 0.1193 - val_accuracy: 0.9659\n",
      "Epoch 18/23\n",
      "108/108 [==============================] - 103s 956ms/step - loss: 0.1523 - accuracy: 0.9556 - val_loss: 0.1135 - val_accuracy: 0.9677\n",
      "Epoch 19/23\n",
      "108/108 [==============================] - 103s 958ms/step - loss: 0.1360 - accuracy: 0.9603 - val_loss: 0.1145 - val_accuracy: 0.9680\n",
      "Epoch 20/23\n",
      "108/108 [==============================] - 105s 975ms/step - loss: 0.1264 - accuracy: 0.9630 - val_loss: 0.1010 - val_accuracy: 0.9726\n",
      "Epoch 21/23\n",
      "108/108 [==============================] - 106s 982ms/step - loss: 0.1187 - accuracy: 0.9654 - val_loss: 0.1053 - val_accuracy: 0.9708\n",
      "Epoch 22/23\n",
      "108/108 [==============================] - 105s 977ms/step - loss: 0.1152 - accuracy: 0.9663 - val_loss: 0.1016 - val_accuracy: 0.9728\n",
      "Epoch 23/23\n",
      "108/108 [==============================] - 103s 954ms/step - loss: 0.1862 - accuracy: 0.9450 - val_loss: 0.1041 - val_accuracy: 0.9726\n",
      "Sample 1:\n",
      "il a vu un vieux camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Il a vu un vieux camion jaune\n",
      "Sample 2:\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external training for model exporting and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daylin/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 15, 128)           25600     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 21, 256)           296448    \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 21, 512)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 21, 345)           176985    \n",
      "=================================================================\n",
      "Total params: 828,761\n",
      "Trainable params: 828,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/23\n",
      "108/108 [==============================] - 103s 911ms/step - loss: 2.4229 - accuracy: 0.4868 - val_loss: 1.5222 - val_accuracy: 0.6062\n",
      "Epoch 2/23\n",
      "108/108 [==============================] - 102s 947ms/step - loss: 1.3954 - accuracy: 0.6289 - val_loss: 1.1714 - val_accuracy: 0.6768\n",
      "Epoch 3/23\n",
      "108/108 [==============================] - 105s 973ms/step - loss: 1.1319 - accuracy: 0.6819 - val_loss: 0.9737 - val_accuracy: 0.7194\n",
      "Epoch 4/23\n",
      "108/108 [==============================] - 104s 962ms/step - loss: 0.9691 - accuracy: 0.7166 - val_loss: 0.8080 - val_accuracy: 0.7584\n",
      "Epoch 5/23\n",
      "108/108 [==============================] - 100s 925ms/step - loss: 0.8718 - accuracy: 0.7380 - val_loss: 0.7033 - val_accuracy: 0.7829\n",
      "Epoch 6/23\n",
      "108/108 [==============================] - 99s 919ms/step - loss: 0.7026 - accuracy: 0.7812 - val_loss: 0.5518 - val_accuracy: 0.8269\n",
      "Epoch 7/23\n",
      "108/108 [==============================] - 100s 924ms/step - loss: 0.7701 - accuracy: 0.7645 - val_loss: 0.5164 - val_accuracy: 0.8390\n",
      "Epoch 8/23\n",
      "108/108 [==============================] - 100s 926ms/step - loss: 0.5522 - accuracy: 0.8244 - val_loss: 0.4147 - val_accuracy: 0.8704\n",
      "Epoch 9/23\n",
      "108/108 [==============================] - 102s 948ms/step - loss: 0.4538 - accuracy: 0.8554 - val_loss: 0.3324 - val_accuracy: 0.8993\n",
      "Epoch 10/23\n",
      "108/108 [==============================] - 104s 966ms/step - loss: 0.4015 - accuracy: 0.8738 - val_loss: 0.3022 - val_accuracy: 0.9097\n",
      "Epoch 11/23\n",
      "108/108 [==============================] - 103s 954ms/step - loss: 0.3145 - accuracy: 0.9050 - val_loss: 0.2319 - val_accuracy: 0.9343\n",
      "Epoch 12/23\n",
      "108/108 [==============================] - 101s 932ms/step - loss: 0.2640 - accuracy: 0.9215 - val_loss: 0.1848 - val_accuracy: 0.9479\n",
      "Epoch 13/23\n",
      "108/108 [==============================] - 96s 892ms/step - loss: 0.5518 - accuracy: 0.8343 - val_loss: 0.2680 - val_accuracy: 0.9298\n",
      "Epoch 14/23\n",
      "108/108 [==============================] - 90s 830ms/step - loss: 0.3121 - accuracy: 0.9069 - val_loss: 0.1832 - val_accuracy: 0.9513\n",
      "Epoch 15/23\n",
      "108/108 [==============================] - 90s 831ms/step - loss: 0.2396 - accuracy: 0.9304 - val_loss: 0.1522 - val_accuracy: 0.9579\n",
      "Epoch 16/23\n",
      "108/108 [==============================] - 90s 829ms/step - loss: 0.2052 - accuracy: 0.9405 - val_loss: 0.1380 - val_accuracy: 0.9618\n",
      "Epoch 17/23\n",
      "108/108 [==============================] - 89s 829ms/step - loss: 0.1811 - accuracy: 0.9473 - val_loss: 0.1244 - val_accuracy: 0.9650\n",
      "Epoch 18/23\n",
      "108/108 [==============================] - 90s 830ms/step - loss: 0.2382 - accuracy: 0.9282 - val_loss: 0.1255 - val_accuracy: 0.9646\n",
      "Epoch 19/23\n",
      "108/108 [==============================] - 90s 830ms/step - loss: 0.1549 - accuracy: 0.9548 - val_loss: 0.1097 - val_accuracy: 0.9689\n",
      "Epoch 20/23\n",
      "108/108 [==============================] - 2094s 20s/step - loss: 0.1368 - accuracy: 0.9598 - val_loss: 0.1055 - val_accuracy: 0.9701\n",
      "Epoch 21/23\n",
      "108/108 [==============================] - 4913s 46s/step - loss: 0.1307 - accuracy: 0.9614 - val_loss: 0.1023 - val_accuracy: 0.9711\n",
      "Epoch 22/23\n",
      "108/108 [==============================] - 90s 837ms/step - loss: 0.1198 - accuracy: 0.9648 - val_loss: 0.0929 - val_accuracy: 0.9737\n",
      "Epoch 23/23\n",
      "108/108 [==============================] - 90s 836ms/step - loss: 0.1109 - accuracy: 0.9673 - val_loss: 0.0919 - val_accuracy: 0.9746\n"
     ]
    }
   ],
   "source": [
    "model = custom_model(preproc_english_sentences.shape, preproc_french_sentences.shape[1],\n",
    "                         len(english_tokenizer.word_index)+1,\n",
    "                         len(french_tokenizer.word_index)+1)\n",
    "model.summary()\n",
    "history = model.fit(preproc_english_sentences, preproc_french_sentences, batch_size=1024, epochs=23, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'he saw a old yellow truck'\n",
    "sentence = [english_tokenizer.word_index[word] for word in sentence.split()]\n",
    "sentence = pad_sequences([sentence], maxlen=preproc_english_sentences.shape[-1], padding='post')\n",
    "sentences = np.array([sentence[0], preproc_english_sentences[0]])\n",
    "predictions = model.predict(sentences, len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
    "y_id_to_word[0] = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "il a vu un vieux camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Il a vu un vieux camion jaune\n",
      "Sample 2:\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print('Sample 1:')\n",
    "print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "print('Il a vu un vieux camion jaune')\n",
    "print('Sample 2:')\n",
    "print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "print(' '.join([y_id_to_word[np.max(x)] for x in preproc_french_sentences[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new single line prediction\n",
    "note = 'he dislikes oranges'\n",
    "note = [english_tokenizer.word_index[word] for word in note.split()]\n",
    "note = pad_sequences([note], maxlen=preproc_english_sentences.shape[-1], padding='post')\n",
    "notes = np.array([note[0], preproc_english_sentences[0]])\n",
    "preds = model.predict(notes, len(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = logits_to_text(preds[0], french_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"il n'aime les oranges <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    sentence = [english_tokenizer.word_index[word] for word in text.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=preproc_english_sentences.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], preproc_english_sentences[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "    decoded_pred = logits_to_text(preds[0], french_tokenizer)\n",
    "    decoded_pred = decoded_pred.replace(' <PAD>', '')\n",
    "    return decoded_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"il n'aime les oranges\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'he dislikes oranges'\n",
    "out = translate(text)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"il n'aime les oranges\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = translate('california is my favorite')\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 1,\n",
       " 'in': 2,\n",
       " 'it': 3,\n",
       " 'during': 4,\n",
       " 'the': 5,\n",
       " 'but': 6,\n",
       " 'and': 7,\n",
       " 'sometimes': 8,\n",
       " 'usually': 9,\n",
       " 'never': 10,\n",
       " 'favorite': 11,\n",
       " 'least': 12,\n",
       " 'fruit': 13,\n",
       " 'most': 14,\n",
       " 'loved': 15,\n",
       " 'liked': 16,\n",
       " 'new': 17,\n",
       " 'paris': 18,\n",
       " 'india': 19,\n",
       " 'united': 20,\n",
       " 'states': 21,\n",
       " 'california': 22,\n",
       " 'jersey': 23,\n",
       " 'france': 24,\n",
       " 'china': 25,\n",
       " 'he': 26,\n",
       " 'she': 27,\n",
       " 'grapefruit': 28,\n",
       " 'your': 29,\n",
       " 'my': 30,\n",
       " 'his': 31,\n",
       " 'her': 32,\n",
       " 'fall': 33,\n",
       " 'june': 34,\n",
       " 'spring': 35,\n",
       " 'january': 36,\n",
       " 'winter': 37,\n",
       " 'march': 38,\n",
       " 'autumn': 39,\n",
       " 'may': 40,\n",
       " 'nice': 41,\n",
       " 'september': 42,\n",
       " 'july': 43,\n",
       " 'april': 44,\n",
       " 'november': 45,\n",
       " 'summer': 46,\n",
       " 'december': 47,\n",
       " 'february': 48,\n",
       " 'our': 49,\n",
       " 'their': 50,\n",
       " 'freezing': 51,\n",
       " 'pleasant': 52,\n",
       " 'beautiful': 53,\n",
       " 'october': 54,\n",
       " 'snowy': 55,\n",
       " 'warm': 56,\n",
       " 'cold': 57,\n",
       " 'wonderful': 58,\n",
       " 'dry': 59,\n",
       " 'busy': 60,\n",
       " 'august': 61,\n",
       " 'chilly': 62,\n",
       " 'rainy': 63,\n",
       " 'mild': 64,\n",
       " 'wet': 65,\n",
       " 'relaxing': 66,\n",
       " 'quiet': 67,\n",
       " 'hot': 68,\n",
       " 'dislikes': 69,\n",
       " 'likes': 70,\n",
       " 'limes': 71,\n",
       " 'lemons': 72,\n",
       " 'grapes': 73,\n",
       " 'mangoes': 74,\n",
       " 'apples': 75,\n",
       " 'peaches': 76,\n",
       " 'oranges': 77,\n",
       " 'pears': 78,\n",
       " 'strawberries': 79,\n",
       " 'bananas': 80,\n",
       " 'to': 81,\n",
       " 'grape': 82,\n",
       " 'apple': 83,\n",
       " 'orange': 84,\n",
       " 'lemon': 85,\n",
       " 'lime': 86,\n",
       " 'banana': 87,\n",
       " 'mango': 88,\n",
       " 'pear': 89,\n",
       " 'strawberry': 90,\n",
       " 'peach': 91,\n",
       " 'like': 92,\n",
       " 'dislike': 93,\n",
       " 'they': 94,\n",
       " 'that': 95,\n",
       " 'i': 96,\n",
       " 'we': 97,\n",
       " 'you': 98,\n",
       " 'animal': 99,\n",
       " 'a': 100,\n",
       " 'truck': 101,\n",
       " 'car': 102,\n",
       " 'automobile': 103,\n",
       " 'was': 104,\n",
       " 'next': 105,\n",
       " 'go': 106,\n",
       " 'driving': 107,\n",
       " 'visit': 108,\n",
       " 'little': 109,\n",
       " 'big': 110,\n",
       " 'old': 111,\n",
       " 'yellow': 112,\n",
       " 'red': 113,\n",
       " 'rusty': 114,\n",
       " 'blue': 115,\n",
       " 'white': 116,\n",
       " 'black': 117,\n",
       " 'green': 118,\n",
       " 'shiny': 119,\n",
       " 'are': 120,\n",
       " 'last': 121,\n",
       " 'feared': 122,\n",
       " 'animals': 123,\n",
       " 'this': 124,\n",
       " 'plan': 125,\n",
       " 'going': 126,\n",
       " 'saw': 127,\n",
       " 'disliked': 128,\n",
       " 'drives': 129,\n",
       " 'drove': 130,\n",
       " 'between': 131,\n",
       " 'translate': 132,\n",
       " 'plans': 133,\n",
       " 'were': 134,\n",
       " 'went': 135,\n",
       " 'might': 136,\n",
       " 'wanted': 137,\n",
       " 'thinks': 138,\n",
       " 'spanish': 139,\n",
       " 'portuguese': 140,\n",
       " 'chinese': 141,\n",
       " 'english': 142,\n",
       " 'french': 143,\n",
       " 'translating': 144,\n",
       " 'difficult': 145,\n",
       " 'fun': 146,\n",
       " 'easy': 147,\n",
       " 'wants': 148,\n",
       " 'think': 149,\n",
       " 'why': 150,\n",
       " \"it's\": 151,\n",
       " 'did': 152,\n",
       " 'cat': 153,\n",
       " 'shark': 154,\n",
       " 'bird': 155,\n",
       " 'mouse': 156,\n",
       " 'horse': 157,\n",
       " 'elephant': 158,\n",
       " 'dog': 159,\n",
       " 'monkey': 160,\n",
       " 'lion': 161,\n",
       " 'bear': 162,\n",
       " 'rabbit': 163,\n",
       " 'snake': 164,\n",
       " 'when': 165,\n",
       " 'want': 166,\n",
       " 'do': 167,\n",
       " 'how': 168,\n",
       " 'elephants': 169,\n",
       " 'horses': 170,\n",
       " 'dogs': 171,\n",
       " 'sharks': 172,\n",
       " 'snakes': 173,\n",
       " 'cats': 174,\n",
       " 'rabbits': 175,\n",
       " 'monkeys': 176,\n",
       " 'bears': 177,\n",
       " 'birds': 178,\n",
       " 'lions': 179,\n",
       " 'mice': 180,\n",
       " \"didn't\": 181,\n",
       " 'eiffel': 182,\n",
       " 'tower': 183,\n",
       " 'grocery': 184,\n",
       " 'store': 185,\n",
       " 'football': 186,\n",
       " 'field': 187,\n",
       " 'lake': 188,\n",
       " 'school': 189,\n",
       " 'would': 190,\n",
       " \"aren't\": 191,\n",
       " 'been': 192,\n",
       " 'weather': 193,\n",
       " 'does': 194,\n",
       " 'has': 195,\n",
       " \"isn't\": 196,\n",
       " 'am': 197,\n",
       " 'where': 198,\n",
       " 'have': 199}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
